# FastAgentMcp

Fast-agent implementation with specialized workflows for various AI agent tasks.

## üì¶ Docker Setup

To run the project using Docker:

1. Build and run with Docker Compose:
   ```bash
   docker-compose up --build
   ```

2. Build the Docker image manually:
   ```bash
   docker build -t fastagent-mcp .
   ```

3. Run the container:
   ```bash
   docker run -p 8080:8080 fastagent-mcp
   ```

The container will automatically run the generic agent. To run specific workflows, use:

```bash
# Run a specific workflow
docker run -p 8080:8080 fastagent-mcp uv run workflow/orchestrator.py

# Save output to a file
docker run -p 8080:8080 fastagent-mcp uv run workflow/orchestrator.py > orchestrator_output.txt
```

## üìÅ Project Structure

- `agent.py`: Generic FastAgent implementation
- `workflow/`: Directory containing specialized agent workflows
  - `router.py`: Task routing workflow
  - `parallel.py`: Parallel processing workflow
  - `evaluator.py`: Agent evaluation workflow
  - `human_input.py`: Human input handling workflow
  - `orchestrator.py`: Multi-agent orchestration workflow

## üõ†Ô∏è Setup Instructions

1. **Install Fast-agent**
   ```bash
   pip install uv
   uv pip install fast-agent-mcp          # install fast-agent
   fast-agent setup                       # create an example agent and config files
   ```

2. **Fill in Configuration Files**
   - `fastagent.config.yaml` - choose your model
   - `fastagent.secrets.yaml`- fill in your API keys (works seamlessly for OpenAI and Anthropic)
      ```yaml
     openai:
        api_key: <your-api-key-here>
      ```

3. **Run the Generic Agent**
   ```bash
   uv run agent.py
   ```

4. **Run a Specialized Workflow e.g. Orchestrator**
   ```bash
   uv run workflow/orchestrator.py
   ```

## üìù Saving Workflow Output

Agent workflows can produce lengthy output. To save the output to a file, use the `>` redirection operator:

```bash
uv run workflow/orchestrator.py > orchestrator_output.txt
```

## ü§ñ Available Workflows

1. **Router**
   - Routes tasks to specialized agents based on the request
   - The routing prompt is automatically generated based on 
   the Agent instructions and available Servers
   

2. **Parallel**
   - Sends the same message to multiple Agents simultaneously (fan-out), then uses the fan-in Agent to process the combined content
   
3. **Evaluator-Optimizer**
   - Two agents combined: one to generate content (the generator), and the other 
   to judge that content and provide actionable feedback (the evaluator). 
   - Messages are sent to the generator first
   - The pair run in a loop until either the evaluator is satisfied 
   with the quality, or the maximum number of refinements is reached. 
   - The final result from the Generator is returned.

4. **Chain**
   - Declarative approach to calling Agents in a sequence

5. **Human Input**
   - Integrates human input into agent workflows
   - Useful for tasks requiring human judgment

6. **Orchestrator**
   - Coordinates multiple agents for complex tasks
   - The planning and aggregation prompts are generated by the Orchestrator,
   which benefits from using more capable models. 
   - Plans can either be built once at the beginning (plantype="full") or iteratively (plantype="iterative").
   Manages agent communication and task delegation

## ‚öôÔ∏è Configuration Options

The project uses `fastagent.config.yaml` for configuration. Key settings include:

- `default_model`: Specifies the default AI model to use
- `logger`: Controls logging behavior
  - `progress_display`: Toggle progress display
  - `show_chat`: Display chat messages
  - `show_tools`: Display tool calls
  - `truncate_tools`: Truncate long tool responses

## üìã Requirements

- Python 3.8+
- FastAgent MCP framework
- Required API keys 
